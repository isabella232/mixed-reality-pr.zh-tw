---
title: 眼球追蹤
description: 瞭解 HoloLens 2 的眼睛追蹤，以及新的人類理解層級（如果提供全像攝影體驗）。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 眼睛追蹤、混合現實、輸入、眼睛、校正、混合現實耳機、windows mixed reality 耳機、虛擬實境耳機、HoloLens、MRTK、混合現實工具組、意圖、動作
ms.openlocfilehash: a4010e5244539909d2b04cdb9e2044672d1decab
ms.sourcegitcommit: c0ba7d7bb57bb5dda65ee9019229b68c2ee7c267
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 05/19/2021
ms.locfileid: "110143241"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="715e0-104">HoloLens 2 的眼球追蹤</span><span class="sxs-lookup"><span data-stu-id="715e0-104">Eye tracking on HoloLens 2</span></span>

![MRTK 中的眼睛追蹤示範](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="715e0-106">HoloLens 2 讓開發人員能夠使用使用者所查看的資訊，讓開發人員能夠使用新的內容層級，並在全像人類的經驗中理解。</span><span class="sxs-lookup"><span data-stu-id="715e0-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability to use information about what the user is looking at.</span></span> <span data-ttu-id="715e0-107">本頁面說明開發人員如何從各種使用案例的眼睛追蹤中獲益，以及設計眼睛型使用者互動時要尋找的內容。</span><span class="sxs-lookup"><span data-stu-id="715e0-107">This page explains how developers can benefit from eye tracking for various use cases, and what to look for when designing eye-gaze-based user interactions.</span></span> 

<span data-ttu-id="715e0-108">眼睛追蹤 API 已設計為使用者的隱私權，避免傳遞任何可識別的資訊，特別是任何生物特徵辨識。</span><span class="sxs-lookup"><span data-stu-id="715e0-108">Eye tracking API has been designed with a user’s privacy in mind, avoiding passing any identifiable information, particularly any biometrics.</span></span> <span data-ttu-id="715e0-109">針對感知感知的應用程式，使用者必須授與應用程式許可權以使用眼睛追蹤資訊。</span><span class="sxs-lookup"><span data-stu-id="715e0-109">For eye-tracking capable applications, the user needs to grant app permission to use eye tracking information.</span></span>

### <a name="device-support"></a><span data-ttu-id="715e0-110">裝置支援</span><span class="sxs-lookup"><span data-stu-id="715e0-110">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="715e0-111"><strong>功能</strong></span><span class="sxs-lookup"><span data-stu-id="715e0-111"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="715e0-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens (第 1 代)</strong></a></span><span class="sxs-lookup"><span data-stu-id="715e0-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="715e0-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="715e0-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="715e0-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>沉浸式頭戴裝置</strong></a></span><span class="sxs-lookup"><span data-stu-id="715e0-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="715e0-115">眼睛</span><span class="sxs-lookup"><span data-stu-id="715e0-115">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="715e0-116">✔️</span><span class="sxs-lookup"><span data-stu-id="715e0-116">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="head-and-eye-tracking-design-concepts-demo"></a><span data-ttu-id="715e0-117">標題和眼睛追蹤設計概念示範</span><span class="sxs-lookup"><span data-stu-id="715e0-117">Head and eye tracking design concepts demo</span></span>

<span data-ttu-id="715e0-118">如果您想要查看前端和眼睛追蹤設計的概念，請參閱下面 [的設計全息圖-標頭追蹤和眼睛追蹤]() 影片示範。</span><span class="sxs-lookup"><span data-stu-id="715e0-118">If you'd like to see Head and Eye Tracking design concepts in action, check out our [Designing Holograms - Head Tracking and Eye Tracking]() video demo below.</span></span> <span data-ttu-id="715e0-119">當您完成時，請繼續進行，以深入瞭解特定主題。</span><span class="sxs-lookup"><span data-stu-id="715e0-119">When you've finished, continue on for a more detailed dive into specific topics.</span></span>

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Microsofts-Designing-Holograms-Head-Tracking-and-Eye-Tracking-Chapter/player]

## <a name="calibration"></a><span data-ttu-id="715e0-120">校正</span><span class="sxs-lookup"><span data-stu-id="715e0-120">Calibration</span></span> 

<span data-ttu-id="715e0-121">為了讓眼睛追蹤能準確地運作，每位使用者都必須經過 [眼睛追蹤使用者校正](/hololens/hololens-calibration) ，讓使用者能夠查看一組全像全像一組的目標。</span><span class="sxs-lookup"><span data-stu-id="715e0-121">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](/hololens/hololens-calibration) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="715e0-122">這可讓裝置為使用者調整系統，以獲得更舒適且更高品質的觀賞體驗，並同時確保一致的眼睛追蹤。</span><span class="sxs-lookup"><span data-stu-id="715e0-122">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> 

<span data-ttu-id="715e0-123">目視追蹤應該適用于大部分的使用者，但在少數情況下，使用者無法成功校正。</span><span class="sxs-lookup"><span data-stu-id="715e0-123">Eye tracking should work for most users, but there are rare cases in which a user can't calibrate successfully.</span></span> <span data-ttu-id="715e0-124">校正可能會因各種原因而失敗，包括但不限於：</span><span class="sxs-lookup"><span data-stu-id="715e0-124">Calibration might fail for various reasons, including but not limited to:</span></span> 
* <span data-ttu-id="715e0-125">使用者先前退出宣告校正流程</span><span class="sxs-lookup"><span data-stu-id="715e0-125">The user previously opted out of the calibration process</span></span>
* <span data-ttu-id="715e0-126">使用者有注意力，未遵循校正目標</span><span class="sxs-lookup"><span data-stu-id="715e0-126">The user got distracted and didn't follow the calibration targets</span></span>
* <span data-ttu-id="715e0-127">使用者有特定類型的 contact 鏡頭和眼鏡，系統尚不支援</span><span class="sxs-lookup"><span data-stu-id="715e0-127">The user has certain types of contact lenses and glasses, which the system doesn't yet support</span></span> 
* <span data-ttu-id="715e0-128">使用者有特定的眼睛生理學、眼睛狀況，或有系統尚未支援的眼睛外科</span><span class="sxs-lookup"><span data-stu-id="715e0-128">The user has certain eye physiology, eye conditions or had eye surgery, which the system doesn't yet support</span></span>  
* <span data-ttu-id="715e0-129">外部因素抑制可靠的眼睛追蹤，例如 HoloLens 面板上的汙跡或眼鏡、密集的直接陽光和遮蔽，因為眼睛正面的頭髮</span><span class="sxs-lookup"><span data-stu-id="715e0-129">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions due to hair in front of the eyes</span></span>

<span data-ttu-id="715e0-130">開發人員應務必為使用者提供適當的支援，讓他們能夠在無法順利校正)  (的情況之下，使用眼睛追蹤資料。</span><span class="sxs-lookup"><span data-stu-id="715e0-130">Developers should make sure to provide adequate support for users for whom eye tracking data may not be available (who aren't able to calibrate successfully).</span></span> <span data-ttu-id="715e0-131">我們已在此頁面底部的區段中，提供回復解決方案的建議。</span><span class="sxs-lookup"><span data-stu-id="715e0-131">We have provided recommendations for fallback solutions in the section at the bottom of this page.</span></span> 

<span data-ttu-id="715e0-132">若要深入瞭解校正，以及如何確保順暢的體驗，請查看我們的 [眼睛追蹤使用者校正](/hololens/hololens-calibration) 頁面。</span><span class="sxs-lookup"><span data-stu-id="715e0-132">To learn more about the calibration and about how to ensure a smooth experience, check our [eye tracking user calibration](/hololens/hololens-calibration) page.</span></span>

<br>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="715e0-133">可用的眼睛追蹤資料</span><span class="sxs-lookup"><span data-stu-id="715e0-133">Available eye tracking data</span></span>

<span data-ttu-id="715e0-134">在深入探討眼睛輸入的特定使用案例之前，我們想要簡短指出 HoloLens 2 的 [眼睛追蹤 API](/uwp/api/windows.perception.people.eyespose) 所提供的功能。</span><span class="sxs-lookup"><span data-stu-id="715e0-134">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="715e0-135">開發人員可存取單一眼睛的光線 (注視的原點和方向) 大約 _30 FPS (30 Hz)_。</span><span class="sxs-lookup"><span data-stu-id="715e0-135">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="715e0-136">如需有關如何存取眼睛追蹤資料的詳細資訊，請參閱我們的開發人員指南，以瞭解如何在您的 [DirectX](../develop/native/gaze-in-directx.md) 和 [Unity 中](https://aka.ms/mrtk-eyes)使用眼睛。</span><span class="sxs-lookup"><span data-stu-id="715e0-136">For more detailed information about how to access eye tracking data, refer to our developer guides for using [eye-gaze in DirectX](../develop/native/gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="715e0-137">預測的眼睛大約是在實際目標 (的視覺角度1.5 度以內，請參閱下圖) 。</span><span class="sxs-lookup"><span data-stu-id="715e0-137">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="715e0-138">由於預期會有些許的 imprecisions，因此開發人員應該規劃這項下限值周圍的一些邊界 (例如，2.0-3.0 度可能會導致) 更熟悉的體驗。</span><span class="sxs-lookup"><span data-stu-id="715e0-138">As slight imprecisions are expected, developers should plan for some margin around this lower-bound value (for example, 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="715e0-139">我們將在下方討論如何處理小型目標的選取。</span><span class="sxs-lookup"><span data-stu-id="715e0-139">We'll discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="715e0-140">為了讓眼球追蹤精準運作，每個使用者都必須接受眼球追蹤使用者校正。</span><span class="sxs-lookup"><span data-stu-id="715e0-140">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="715e0-141">![距離 2 公尺的最佳目標大小](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="715e0-141">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="715e0-142">*雙計量距離的最佳目標大小*</span><span class="sxs-lookup"><span data-stu-id="715e0-142">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="715e0-143">使用案例</span><span class="sxs-lookup"><span data-stu-id="715e0-143">Use cases</span></span>

<span data-ttu-id="715e0-144">眼球追蹤可讓應用程式即時追蹤使用者的視線方向。</span><span class="sxs-lookup"><span data-stu-id="715e0-144">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="715e0-145">下列使用案例說明在混合現實 HoloLens 2 上進行眼追蹤時可能發生的一些互動。</span><span class="sxs-lookup"><span data-stu-id="715e0-145">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="715e0-146">這些使用案例還不是全像 Shell 體驗的一部分 (也就是當您啟動 HoloLens 2) 時所看到的介面。</span><span class="sxs-lookup"><span data-stu-id="715e0-146">These use cases aren't yet part of the Holographic Shell experience (that is, the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="715e0-147">您可以在「 [混合現實」工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組中試用其中一部分，這會提供數個有趣且功能強大的範例來使用眼睛追蹤，例如快速且輕鬆地顯示支援的目標選取專案，並根據使用者的外觀自動滾動文字。</span><span class="sxs-lookup"><span data-stu-id="715e0-147">You can try some of them in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html), which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections, and automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="715e0-148">使用者意圖</span><span class="sxs-lookup"><span data-stu-id="715e0-148">User intent</span></span>

<span data-ttu-id="715e0-149">使用者查看位置和內容的相關資訊，可 **為其他輸入** 提供功能強大的內容，例如語音、手和控制器。</span><span class="sxs-lookup"><span data-stu-id="715e0-149">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands, and controllers.</span></span>
<span data-ttu-id="715e0-150">這可以運用在各種不同的工作上。</span><span class="sxs-lookup"><span data-stu-id="715e0-150">This can be used for various tasks.</span></span>
<span data-ttu-id="715e0-151">比方說，這可以透過查看一組影像並說「*選取*」 (也可以快速且輕鬆地以場景為 **目標**，也就是查看 [和認可](gaze-and-commit.md)) 或「 *put this ...*」，然後查看使用者想要放置全像 *有*。</span><span class="sxs-lookup"><span data-stu-id="715e0-151">For example, this can range from quickly and effortlessly **targeting** across the scene by looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="715e0-152">您可以在[混合實境工具組 - 視線導向目標選取](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)和[混合實境工具組 - 視線導向目標定位](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)中找到相關範例。</span><span class="sxs-lookup"><span data-stu-id="715e0-152">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="715e0-153">此外，使用者意圖的範例可能包括使用使用者查看的相關資訊，以增強與各有虛擬專員和互動式全息的互動。</span><span class="sxs-lookup"><span data-stu-id="715e0-153">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="715e0-154">例如，虛擬專員可能會根據目前已查看的內容，來調整可用的選項和其行為。</span><span class="sxs-lookup"><span data-stu-id="715e0-154">For instance, virtual agents might adapt available options and their behavior, based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="715e0-155">隱含動作</span><span class="sxs-lookup"><span data-stu-id="715e0-155">Implicit actions</span></span>

<span data-ttu-id="715e0-156">隱含動作的類別與使用者意圖有密切的關係。</span><span class="sxs-lookup"><span data-stu-id="715e0-156">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="715e0-157">它的概念是，全像是全像是 instinctual 的影像或使用者介面專案，可能不會覺得使用者完全與系統互動，而是由系統和使用者保持同步。其中一個範例是以 **眼睛為基礎的自動滾動** ，其中使用者可以讀取長文字，這會在使用者到達文字方塊底部時自動開始滾動，以將使用者保持在閱讀流程中，而不需要抬起手指。</span><span class="sxs-lookup"><span data-stu-id="715e0-157">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text, which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading, without lifting a finger.</span></span>  
<span data-ttu-id="715e0-158">其中一個重要層面是，捲動速度會調整為使用者的閱讀速度。</span><span class="sxs-lookup"><span data-stu-id="715e0-158">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="715e0-159">另一個範例是 **眼睛支援的縮放和平移** ，讓使用者可以覺得完全朝著他或她的焦點。</span><span class="sxs-lookup"><span data-stu-id="715e0-159">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she's focused on.</span></span> <span data-ttu-id="715e0-160">觸發和控制縮放速度可透過聲音或手寫輸入來控制，這對於提供使用者感覺來掌控控制項，同時避免發生大量的情況相當重要。</span><span class="sxs-lookup"><span data-stu-id="715e0-160">Triggering and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="715e0-161">我們將在下面更詳細討論這些設計考慮。</span><span class="sxs-lookup"><span data-stu-id="715e0-161">We'll talk about these design considerations in more detail below.</span></span> <span data-ttu-id="715e0-162">放大之後，使用者可以順暢地遵循，例如，街道的某一堂，使用眼睛的眼睛來探索其鄰近地區。</span><span class="sxs-lookup"><span data-stu-id="715e0-162">Once zoomed in, the user can smoothly follow, for example, the course of a street to explore his or her neighborhood by using their eye-gaze.</span></span>
<span data-ttu-id="715e0-163">您可以在[混合實境工具組 - 視線導向瀏覽](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)範例中找到這類互動的示範。</span><span class="sxs-lookup"><span data-stu-id="715e0-163">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="715e0-164">其他 _隱含動作_ 的使用案例可能包括：</span><span class="sxs-lookup"><span data-stu-id="715e0-164">Other use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="715e0-165">**智慧型通知：** 在您想要的位置上快顯通知的感到苦惱？</span><span class="sxs-lookup"><span data-stu-id="715e0-165">**Smart notifications:** Ever get annoyed by notifications popping up right where you're looking?</span></span> <span data-ttu-id="715e0-166">考慮到使用者所注意的內容，您可以藉由從使用者目前撥雲見日的位置來抵銷通知，讓這項體驗更好。</span><span class="sxs-lookup"><span data-stu-id="715e0-166">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="715e0-167">這會限制分散注意力，並在使用者完成閱讀之後自動將其關閉。</span><span class="sxs-lookup"><span data-stu-id="715e0-167">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="715e0-168">**用心全像影像：** Gazed 時，會稍微反應的全像投影。</span><span class="sxs-lookup"><span data-stu-id="715e0-168">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="715e0-169">這可以從稍微照亮的 UI 元素範圍內，以緩慢的綻放花卉為虛擬狗，從使用者回頭看看，並 wagging 它的結尾。</span><span class="sxs-lookup"><span data-stu-id="715e0-169">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="715e0-170">這項互動可能會在您的應用程式中提供連線能力和滿意度的有趣意義。</span><span class="sxs-lookup"><span data-stu-id="715e0-170">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="715e0-171">注意力追蹤</span><span class="sxs-lookup"><span data-stu-id="715e0-171">Attention tracking</span></span>

<span data-ttu-id="715e0-172">使用者所查看之位置或位置的資訊，是一種功能強大的工具。</span><span class="sxs-lookup"><span data-stu-id="715e0-172">Information on where or what users look at can be an immensely powerful tool.</span></span> <span data-ttu-id="715e0-173">它有助於評估設計的可用性，並識別工作流程中的問題，使其更有效率。</span><span class="sxs-lookup"><span data-stu-id="715e0-173">It can help assess usability of designs and identify problems in workflows to make them more efficient.</span></span>
<span data-ttu-id="715e0-174">目視追蹤視覺效果和分析是各種應用程式區域中常見的作法。</span><span class="sxs-lookup"><span data-stu-id="715e0-174">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="715e0-175">有了 HoloLens 2，我們會提供新的維度來瞭解這一點，因為3D 全息圖可放置在真實世界的內容中，並據以進行評估。</span><span class="sxs-lookup"><span data-stu-id="715e0-175">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="715e0-176">[Mixed Reality 工具](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)組提供記錄和載入眼睛追蹤資料的基本範例，以及如何將其視覺化。</span><span class="sxs-lookup"><span data-stu-id="715e0-176">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>
<span data-ttu-id="715e0-177">Microsoft 致力於促進創新，同時確保使用者對其眼睛追蹤資訊的使用方式有明智且透明的體驗。</span><span class="sxs-lookup"><span data-stu-id="715e0-177">Microsoft is dedicated to facilitating innovation while ensuring that users have an informed and transparent experience with how their eye tracking information is used.</span></span>  <span data-ttu-id="715e0-178">我們將與我們的開發人員和 UX 小組合作，為協力廠商提供指導方針，以確保體驗是以使用者為中心。</span><span class="sxs-lookup"><span data-stu-id="715e0-178">We'll work with our developers and UX teams to provide guidance for third parties to ensure that experiences are centered around the user.</span></span>  

<span data-ttu-id="715e0-179">同屬此領域的其他應用程式包括：</span><span class="sxs-lookup"><span data-stu-id="715e0-179">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="715e0-180">**遠端眼睛視覺效果：** 遠端眼睛視覺效果：視覺化遠端共同作業者所關注的內容，以提供立即的意見反應，並協助更精確的資訊處理。</span><span class="sxs-lookup"><span data-stu-id="715e0-180">**Remote eye-gaze visualization:** Remote eye-gaze visualizations: Visualize what remote collaborators are looking at, to be able to provide immediate feedback and facilitate more accurate information processing.</span></span>
-   <span data-ttu-id="715e0-181">**使用者研究研究：** 注意追蹤可協助研究人員深入瞭解使用者如何觀察並與自然環境互動，而不會干擾如何設計更 instinctual 的人類電腦互動。</span><span class="sxs-lookup"><span data-stu-id="715e0-181">**User research studies:** Attention tracking can help researchers get more insights into how users perceive and engage with the natural environment, without interfering, to design more instinctual human-computer-interactions.</span></span> <span data-ttu-id="715e0-182">目視追蹤可以提供在研究中的參與者未直接表達的資訊，但研究員可能很容易錯過。</span><span class="sxs-lookup"><span data-stu-id="715e0-182">Eye tracking can provide information that is not directly articulated by participants in the study, which otherwise might be easily missed by the researcher.</span></span> 
-   <span data-ttu-id="715e0-183">**訓練和效能監視：** 藉由在執行流程中更有效地找出瓶頸，來練習並將工作的執行優化。</span><span class="sxs-lookup"><span data-stu-id="715e0-183">**Training and performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span> <span data-ttu-id="715e0-184">目視追蹤可提供自然、即時和目標的資訊，以協助改善工作場所的訓練、生產力和安全性。</span><span class="sxs-lookup"><span data-stu-id="715e0-184">Eye tracking can provide natural, real-time, and objective information to help improve training, productivity, and safety in the workplace.</span></span> 
-   <span data-ttu-id="715e0-185">**設計評估、行銷和取用者研究：** 目視追蹤可讓商業公司在真實世界的環境中執行行銷和取用者研究，或分析哪些東西會讓使用者注意，以改善產品或空間的設計。</span><span class="sxs-lookup"><span data-stu-id="715e0-185">**Design evaluations, marketing, and consumer research:** Eye tracking enables commercial companies to perform marketing and consumer studies in real-world environments or analyze what captures a user’s attention to improve product or space design.</span></span> 

### <a name="other-use-cases"></a><span data-ttu-id="715e0-186">其他使用案例</span><span class="sxs-lookup"><span data-stu-id="715e0-186">Other use cases</span></span>

- <span data-ttu-id="715e0-187">**遊戲：** 希望有超能力嗎？</span><span class="sxs-lookup"><span data-stu-id="715e0-187">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="715e0-188">機會來了！</span><span class="sxs-lookup"><span data-stu-id="715e0-188">Here's your chance!</span></span> <span data-ttu-id="715e0-189">您可以透過開始來 levitate 全像投影。</span><span class="sxs-lookup"><span data-stu-id="715e0-189">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="715e0-190">從您的眼睛放大鐳射字形狀-在 RoboRaid 中試用以 [進行 HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)。</span><span class="sxs-lookup"><span data-stu-id="715e0-190">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="715e0-191">將敵人變成石頭或凍結它們。</span><span class="sxs-lookup"><span data-stu-id="715e0-191">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="715e0-192">您可以用 X 光視線掃描建築物。</span><span class="sxs-lookup"><span data-stu-id="715e0-192">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="715e0-193">您想得到的都行！</span><span class="sxs-lookup"><span data-stu-id="715e0-193">Your imagination is the limit!</span></span>
<span data-ttu-id="715e0-194">要注意的是，不讓使用者覺得更多，請查看我們的 [眼睛型輸入設計指導方針](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="715e0-194">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="715e0-195">**表達虛擬人偶：** 眼睛追蹤可協助更具表達性的3D 虛擬人偶，方法是使用即時眼睛追蹤資料，以動畫顯示使用者所查看的內容。</span><span class="sxs-lookup"><span data-stu-id="715e0-195">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="715e0-196">**文字輸入：** 您可以使用眼睛追蹤作為低工作量文字輸入的替代方案，特別是當語音或手手不方便使用時。</span><span class="sxs-lookup"><span data-stu-id="715e0-196">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="715e0-197">使用眼睛進行互動</span><span class="sxs-lookup"><span data-stu-id="715e0-197">Using eye-gaze for interaction</span></span>

<span data-ttu-id="715e0-198">建立利用快速移動眼睛目標的互動可能是一項挑戰。</span><span class="sxs-lookup"><span data-stu-id="715e0-198">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="715e0-199">一方面，眼睛的移動速度很快，您需要特別注意如何使用眼睛的輸入，因為使用者可能會發現經驗太過或混亂。</span><span class="sxs-lookup"><span data-stu-id="715e0-199">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise users may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="715e0-200">另一方面，您也可以建立真正的神奇體驗，將激發您的使用者！</span><span class="sxs-lookup"><span data-stu-id="715e0-200">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="715e0-201">為協助您，請查看我們的主要優點、挑戰和設計建議，以進行 [互動](eye-gaze-interaction.md)。</span><span class="sxs-lookup"><span data-stu-id="715e0-201">To help you, check out our overview of key advantages, challenges, and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 
 
## <a name="fallback-solutions-when-eye-tracking-isnt-available"></a><span data-ttu-id="715e0-202">當眼睛追蹤無法使用時的回溯解決方案</span><span class="sxs-lookup"><span data-stu-id="715e0-202">Fallback solutions when eye tracking isn't available</span></span>

<span data-ttu-id="715e0-203">在罕見的情況下，可能無法使用眼睛追蹤資料。</span><span class="sxs-lookup"><span data-stu-id="715e0-203">In rare cases, eye tracking data might not be available.</span></span>
<span data-ttu-id="715e0-204">這可能是因為下列各項最常見的原因：</span><span class="sxs-lookup"><span data-stu-id="715e0-204">This can be because of different reasons from which the most common are listed below:</span></span>
* <span data-ttu-id="715e0-205">系統無法 [校正使用者](/hololens/hololens-calibration)。</span><span class="sxs-lookup"><span data-stu-id="715e0-205">The system failed to [calibrate the user](/hololens/hololens-calibration).</span></span>
* <span data-ttu-id="715e0-206">使用者略過 [校正](/hololens/hololens-calibration)。</span><span class="sxs-lookup"><span data-stu-id="715e0-206">The user skipped the [calibration](/hololens/hololens-calibration).</span></span>   
* <span data-ttu-id="715e0-207">已校正使用者，但決定不授與應用程式使用其眼睛追蹤資料的許可權。</span><span class="sxs-lookup"><span data-stu-id="715e0-207">The user is calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>    
* <span data-ttu-id="715e0-208">使用者有唯一的眼鏡或某些系統尚未支援的眼睛狀況。</span><span class="sxs-lookup"><span data-stu-id="715e0-208">The user has unique eyeglasses or some eye condition that the system doesn't yet support.</span></span> 
* <span data-ttu-id="715e0-209">外部因素抑制可靠的眼睛追蹤，例如 HoloLens 面板上的汙跡或眼鏡、密集的直接陽光和遮蔽，因為眼睛正面的頭髮。</span><span class="sxs-lookup"><span data-stu-id="715e0-209">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions because of hair in front of the eyes.</span></span>

<span data-ttu-id="715e0-210">開發人員應該確保這些使用者有適當的回溯支援。</span><span class="sxs-lookup"><span data-stu-id="715e0-210">Developers should ensure that there's appropriate fallback support for these users.</span></span> <span data-ttu-id="715e0-211">在 [ [DirectX 中的眼睛追蹤](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) ] 頁面上，我們會說明偵測是否有眼睛追蹤資料的必要 api。</span><span class="sxs-lookup"><span data-stu-id="715e0-211">On the [Eye Tracking in DirectX](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) page, we explain the APIs required to detect whether eye tracking data is available.</span></span> 

<span data-ttu-id="715e0-212">雖然某些使用者可能會基本思考模式決定要撤銷，但在某些情況下，您可能會不小心地存取其眼睛追蹤資料，並可在不提供存取權限的情況下權衡使用者體驗的隱私權。</span><span class="sxs-lookup"><span data-stu-id="715e0-212">While some users may have consciously decided to revoke,  access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="715e0-213">如果您的應用程式使用眼睛追蹤，而且這是體驗的重要部分，我們建議您明確地將此資訊傳達給使用者。</span><span class="sxs-lookup"><span data-stu-id="715e0-213">If your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span>   

<span data-ttu-id="715e0-214">請通知使用者，為什麼眼睛追蹤對您的應用程式而言是很重要的 (甚至可以列出一些增強的功能) ，以充分利用您的應用程式，協助使用者更瞭解他們所放棄的功能。</span><span class="sxs-lookup"><span data-stu-id="715e0-214">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application, can help the user to better understand what they're giving up.</span></span> <span data-ttu-id="715e0-215">協助使用者根據上述的檢查) ，找出可能無法 (眼睛追蹤的原因，並提供一些建議來快速排解可能的問題。</span><span class="sxs-lookup"><span data-stu-id="715e0-215">Help the user identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> 

<span data-ttu-id="715e0-216">比方說，如果您可以偵測到系統支援眼睛追蹤，則使用者會經過校正並獲得其許可權，但不會收到任何眼睛追蹤資料，而這可能會指向一些其他問題，例如汙跡或眼睛 pixels occluded。</span><span class="sxs-lookup"><span data-stu-id="715e0-216">For example, if you can detect that the system supports eye tracking, the user is calibrated and has even given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> 

<span data-ttu-id="715e0-217">在罕見的情況下，眼睛追蹤可能無法運作的使用者。</span><span class="sxs-lookup"><span data-stu-id="715e0-217">There are rare cases of users for whom eye tracking may not work.</span></span> <span data-ttu-id="715e0-218">因此，請尊重，允許關閉或甚至停用在應用程式中啟用眼睛追蹤的提醒。</span><span class="sxs-lookup"><span data-stu-id="715e0-218">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="fall-back-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="715e0-219">使用眼睛作為主要輸入指標來切換回應用程式</span><span class="sxs-lookup"><span data-stu-id="715e0-219">Fall back for apps using eye-gaze as a primary input pointer</span></span>

<span data-ttu-id="715e0-220">如果您的應用程式使用眼睛來做為指標輸入，以快速地選取整個場景的全像投影，但無法使用眼睛追蹤資料，我們建議您回到頁首，然後開始顯示頭部眼的游標。</span><span class="sxs-lookup"><span data-stu-id="715e0-220">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="715e0-221">我們建議使用 timeout (例如，500-1500 ms) 來判斷是否要切換。</span><span class="sxs-lookup"><span data-stu-id="715e0-221">We recommend using a timeout (for example, 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="715e0-222">此動作可防止每次系統因為快速的操作或動畫快遞或閃爍而短暫遺失追蹤時，就會出現資料指標。</span><span class="sxs-lookup"><span data-stu-id="715e0-222">This action prevents cursors from appearing every time the system may briefly lose tracking because of fast eye motions or winks and blinks.</span></span> <span data-ttu-id="715e0-223">如果您是 Unity 開發人員，則已在混合現實工具組中處理自動回復至前端。</span><span class="sxs-lookup"><span data-stu-id="715e0-223">If you're a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="715e0-224">如果您是 DirectX 開發人員，您必須自行處理此參數。</span><span class="sxs-lookup"><span data-stu-id="715e0-224">If you're a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="fall-back-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="715e0-225">切換回其他眼睛追蹤特定應用程式</span><span class="sxs-lookup"><span data-stu-id="715e0-225">Fall back for other eye-tracking-specific applications</span></span>

<span data-ttu-id="715e0-226">您的應用程式可能會以專為眼睛量身打造的獨特方式來使用眼睛。</span><span class="sxs-lookup"><span data-stu-id="715e0-226">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes.</span></span> <span data-ttu-id="715e0-227">例如，以動畫顯示圖片的眼睛，或是基於眼睛的注意，熱度圖依賴視覺效果的精確資訊。</span><span class="sxs-lookup"><span data-stu-id="715e0-227">For example, animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="715e0-228">在此情況下，不會有明確的回復。</span><span class="sxs-lookup"><span data-stu-id="715e0-228">In this case, there's no clear fallback.</span></span> <span data-ttu-id="715e0-229">如果無法使用眼睛追蹤，可能需要停用這些功能。</span><span class="sxs-lookup"><span data-stu-id="715e0-229">If eye tracking isn't available, these capabilities may need to be disabled.</span></span>
<span data-ttu-id="715e0-230">同樣地，我們建議您清楚地與可能不知道功能無法運作的使用者溝通。</span><span class="sxs-lookup"><span data-stu-id="715e0-230">Again, we recommend to clearly communicate this to the user who may be unaware that the capability isn't working.</span></span>

<br>

<span data-ttu-id="715e0-231">此頁面希望您有大致的瞭解，讓您開始瞭解 HoloLens 2 的眼睛追蹤和眼睛輸入的角色。</span><span class="sxs-lookup"><span data-stu-id="715e0-231">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="715e0-232">若要開始進行開發，請查看有關眼睛的資訊，以瞭解如何與全像 [影像互動](eye-gaze-interaction.md)、 [在 Unity 中的眼睛](https://aka.ms/mrtk-eyes) ，以及 [DirectX 中的眼睛](../develop/native/gaze-in-directx.md)。</span><span class="sxs-lookup"><span data-stu-id="715e0-232">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](../develop/native/gaze-in-directx.md).</span></span>

## <a name="see-also"></a><span data-ttu-id="715e0-233">另請參閱</span><span class="sxs-lookup"><span data-stu-id="715e0-233">See also</span></span>

* [<span data-ttu-id="715e0-234">校正</span><span class="sxs-lookup"><span data-stu-id="715e0-234">Calibration</span></span>](/hololens/hololens-calibration)
* [<span data-ttu-id="715e0-235">舒適度</span><span class="sxs-lookup"><span data-stu-id="715e0-235">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="715e0-236">眼部目光導向的互動</span><span class="sxs-lookup"><span data-stu-id="715e0-236">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="715e0-237">DirectX 中的眼睛</span><span class="sxs-lookup"><span data-stu-id="715e0-237">Eye-gaze in DirectX</span></span>](../develop/native/gaze-in-directx.md)
* [<span data-ttu-id="715e0-238">Unity 中的眼睛 (混合現實工具組) </span><span class="sxs-lookup"><span data-stu-id="715e0-238">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="715e0-239">目光和行動</span><span class="sxs-lookup"><span data-stu-id="715e0-239">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="715e0-240">語音輸入</span><span class="sxs-lookup"><span data-stu-id="715e0-240">Voice input</span></span>](../out-of-scope/voice-design.md)
